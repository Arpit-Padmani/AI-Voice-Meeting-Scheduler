{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Speech to Text using speech_recognition",
   "id": "fb9f098d183b8fcb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T11:39:50.274724Z",
     "start_time": "2025-06-30T11:39:44.470872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import speech_recognition as sr\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Use the default microphone as the audio source\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Say something!\")\n",
    "    r.adjust_for_ambient_noise(source)\n",
    "    audio = r.listen(source)\n",
    "    print(\"Time over, thanks\")\n",
    "\n",
    "try:\n",
    "    text = r.recognize_google(audio)\n",
    "    print(f\"You said: {text}\")\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Sorry, I did not get that\")\n",
    "except sr.RequestError as e:\n",
    "    print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
    "\n"
   ],
   "id": "98475baf3e7bb1d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something!\n",
      "Time over, thanks\n",
      "You said: schedule marketing at 3:00\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for index, name in enumerate(sr.Microphone.list_microphone_names()):\n",
    "    print(\"Microphone with name \\\"{1}\\\" found for `Microphone(device_index={0})`\".format(index, name))"
   ],
   "id": "cefd48f9af972b11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Text to Speech Using pyttsx3",
   "id": "45b89987a408519b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# pip install pypiwin32",
   "id": "b75d0ed593f9619a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T14:36:04.246704Z",
     "start_time": "2025-06-29T14:36:03.240100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pyttsx3\n",
    "engine = pyttsx3.init()"
   ],
   "id": "4a8248adcc4b1860",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rate = engine.getProperty('rate')\n",
    "engine.setProperty('rate', rate - 50)\n",
    "engine.setProperty('volume', 1)\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[0].id)"
   ],
   "id": "992f8292ad737911",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "engine.say(\"Hello sir, set my meeting at 3:45:25 PM .\")\n",
    "engine.runAndWait()"
   ],
   "id": "a17ec4b317ccc633",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Chnaging Voice",
   "id": "b43dd0d76fce00f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "engine = pyttsx3.init()\n",
    "voices = engine.getProperty('voices')\n",
    "for voice in voices:\n",
    "   engine.setProperty('voice', voice.id)\n",
    "   engine.say('The quick brown fox jumped over the lazy dog.')\n",
    "engine.runAndWait()"
   ],
   "id": "399759811365bb1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Simple Voice command",
   "id": "d4f9540730092974"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T14:54:11.258721Z",
     "start_time": "2025-06-29T14:53:17.620081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import speech_recognition as sr\n",
    "import subprocess\n",
    "\n",
    "# Initialize the recognizer\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Function to listen to audio input and perform actions\n",
    "def listen_and_execute():\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        try:\n",
    "            audio = recognizer.listen(source, timeout=5)  # Adjust the timeout as needed\n",
    "            print(\"Processing...\")\n",
    "            # Use a speech recognition engine to convert audio to text\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            print(\"You said:\", text)\n",
    "\n",
    "            # Define commands based on recognized text\n",
    "            if \"open notepad\" in text.lower():\n",
    "                subprocess.Popen([\"notepad.exe\"])\n",
    "            elif \"open calculator\" in text.lower():\n",
    "                subprocess.Popen([\"calc.exe\"])\n",
    "            # Add more commands as needed\n",
    "\n",
    "        except sr.WaitTimeoutError:\n",
    "            print(\"Timed out. No speech detected.\")\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Sorry, could not understand audio.\")\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred:\", str(e))\n",
    "\n",
    "# Main loop for continuous listening\n",
    "while True:\n",
    "    listen_and_execute()"
   ],
   "id": "a53aa854eb1f452",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Processing...\n",
      "Sorry, could not understand audio.\n",
      "Listening...\n",
      "Processing...\n",
      "You said: open Notepad\n",
      "Listening...\n",
      "Processing...\n",
      "You said: close notepad\n",
      "Listening...\n",
      "Processing...\n",
      "Sorry, could not understand audio.\n",
      "Listening...\n",
      "Processing...\n",
      "You said: open calculator\n",
      "Listening...\n",
      "Processing...\n",
      "Sorry, could not understand audio.\n",
      "Listening...\n",
      "Processing...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 34\u001B[39m\n\u001B[32m     32\u001B[39m \u001B[38;5;66;03m# Main loop for continuous listening\u001B[39;00m\n\u001B[32m     33\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m34\u001B[39m     \u001B[43mlisten_and_execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 15\u001B[39m, in \u001B[36mlisten_and_execute\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     13\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mProcessing...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     14\u001B[39m \u001B[38;5;66;03m# Use a speech recognition engine to convert audio to text\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m text = \u001B[43mrecognizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrecognize_google\u001B[49m\u001B[43m(\u001B[49m\u001B[43maudio\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     16\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mYou said:\u001B[39m\u001B[33m\"\u001B[39m, text)\n\u001B[32m     18\u001B[39m \u001B[38;5;66;03m# Define commands based on recognized text\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\Speech Recognition python\\.venv\\Lib\\site-packages\\speech_recognition\\recognizers\\google.py:253\u001B[39m, in \u001B[36mrecognize_legacy\u001B[39m\u001B[34m(recognizer, audio_data, key, language, pfilter, show_all, with_confidence, endpoint)\u001B[39m\n\u001B[32m    236\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Performs speech recognition on ``audio_data`` (an ``AudioData`` instance), using the Google Speech Recognition API.\u001B[39;00m\n\u001B[32m    237\u001B[39m \n\u001B[32m    238\u001B[39m \u001B[33;03mThe Google Speech Recognition API key is specified by ``key``. If not specified, it uses a generic key that works out of the box. This should generally be used for personal or testing purposes only, as it **may be revoked by Google at any time**.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    248\u001B[39m \u001B[33;03mRaises a ``speech_recognition.UnknownValueError`` exception if the speech is unintelligible. Raises a ``speech_recognition.RequestError`` exception if the speech recognition operation failed, if the key isn't valid, or if there is no internet connection.\u001B[39;00m\n\u001B[32m    249\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    250\u001B[39m request_builder = create_request_builder(\n\u001B[32m    251\u001B[39m     endpoint=endpoint, key=key, language=language, filter_level=pfilter\n\u001B[32m    252\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m253\u001B[39m request = \u001B[43mrequest_builder\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbuild\u001B[49m\u001B[43m(\u001B[49m\u001B[43maudio_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    255\u001B[39m response_text = obtain_transcription(\n\u001B[32m    256\u001B[39m     request, timeout=recognizer.operation_timeout\n\u001B[32m    257\u001B[39m )\n\u001B[32m    259\u001B[39m output_parser = OutputParser(\n\u001B[32m    260\u001B[39m     show_all=show_all, with_confidence=with_confidence\n\u001B[32m    261\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\Speech Recognition python\\.venv\\Lib\\site-packages\\speech_recognition\\recognizers\\google.py:56\u001B[39m, in \u001B[36mRequestBuilder.build\u001B[39m\u001B[34m(self, audio_data)\u001B[39m\n\u001B[32m     54\u001B[39m url = \u001B[38;5;28mself\u001B[39m.build_url()\n\u001B[32m     55\u001B[39m headers = \u001B[38;5;28mself\u001B[39m.build_headers(audio_data)\n\u001B[32m---> \u001B[39m\u001B[32m56\u001B[39m flac_data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbuild_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43maudio_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     57\u001B[39m request = Request(url, data=flac_data, headers=headers)\n\u001B[32m     58\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m request\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\Speech Recognition python\\.venv\\Lib\\site-packages\\speech_recognition\\recognizers\\google.py:88\u001B[39m, in \u001B[36mRequestBuilder.build_data\u001B[39m\u001B[34m(self, audio_data)\u001B[39m\n\u001B[32m     87\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mbuild_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, audio_data: AudioData) -> \u001B[38;5;28mbytes\u001B[39m:\n\u001B[32m---> \u001B[39m\u001B[32m88\u001B[39m     flac_data = \u001B[43maudio_data\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_flac_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     89\u001B[39m \u001B[43m        \u001B[49m\u001B[43mconvert_rate\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mto_convert_rate\u001B[49m\u001B[43m(\u001B[49m\u001B[43maudio_data\u001B[49m\u001B[43m.\u001B[49m\u001B[43msample_rate\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     90\u001B[39m \u001B[43m        \u001B[49m\u001B[43mconvert_width\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# audio samples must be 16-bit\u001B[39;49;00m\n\u001B[32m     91\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     92\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m flac_data\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\Speech Recognition python\\.venv\\Lib\\site-packages\\speech_recognition\\audio.py:268\u001B[39m, in \u001B[36mAudioData.get_flac_data\u001B[39m\u001B[34m(self, convert_rate, convert_width)\u001B[39m\n\u001B[32m    255\u001B[39m     startup_info = \u001B[38;5;28;01mNone\u001B[39;00m  \u001B[38;5;66;03m# default startupinfo\u001B[39;00m\n\u001B[32m    256\u001B[39m process = subprocess.Popen(\n\u001B[32m    257\u001B[39m     [\n\u001B[32m    258\u001B[39m         flac_converter,\n\u001B[32m   (...)\u001B[39m\u001B[32m    266\u001B[39m     startupinfo=startup_info,\n\u001B[32m    267\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m268\u001B[39m flac_data, stderr = \u001B[43mprocess\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcommunicate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwav_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    269\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m flac_data\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\anaconda\\Lib\\subprocess.py:1209\u001B[39m, in \u001B[36mPopen.communicate\u001B[39m\u001B[34m(self, input, timeout)\u001B[39m\n\u001B[32m   1206\u001B[39m     endtime = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1208\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1209\u001B[39m     stdout, stderr = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_communicate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mendtime\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1210\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[32m   1211\u001B[39m     \u001B[38;5;66;03m# https://bugs.python.org/issue25942\u001B[39;00m\n\u001B[32m   1212\u001B[39m     \u001B[38;5;66;03m# See the detailed comment in .wait().\u001B[39;00m\n\u001B[32m   1213\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\anaconda\\Lib\\subprocess.py:1622\u001B[39m, in \u001B[36mPopen._communicate\u001B[39m\u001B[34m(self, input, endtime, orig_timeout)\u001B[39m\n\u001B[32m   1619\u001B[39m     \u001B[38;5;28mself\u001B[39m.stderr_thread.start()\n\u001B[32m   1621\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.stdin:\n\u001B[32m-> \u001B[39m\u001B[32m1622\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_stdin_write\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   1624\u001B[39m \u001B[38;5;66;03m# Wait for the reader threads, or time out.  If we time out, the\u001B[39;00m\n\u001B[32m   1625\u001B[39m \u001B[38;5;66;03m# threads remain reading and the fds left open in case the user\u001B[39;00m\n\u001B[32m   1626\u001B[39m \u001B[38;5;66;03m# calls communicate again.\u001B[39;00m\n\u001B[32m   1627\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.stdout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\anaconda\\Lib\\subprocess.py:1143\u001B[39m, in \u001B[36mPopen._stdin_write\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m   1141\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28minput\u001B[39m:\n\u001B[32m   1142\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1143\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstdin\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   1144\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBrokenPipeError\u001B[39;00m:\n\u001B[32m   1145\u001B[39m         \u001B[38;5;28;01mpass\u001B[39;00m  \u001B[38;5;66;03m# communicate() must ignore broken pipe errors.\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bbf8aadc240e4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
